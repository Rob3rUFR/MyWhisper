# ğŸ¤ MyWhisper - Transcription Audio avec IA

Conteneur Docker plug-and-play pour la transcription audio utilisant **Faster Whisper Large v3** avec diarisation des speakers via **NVIDIA NeMo Sortformer** et post-traitement via **Ollama**.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110-green)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![CUDA](https://img.shields.io/badge/CUDA-12.4-76B900)

## âœ¨ FonctionnalitÃ©s

### Transcription
- ğŸ¯ **Faster Whisper Large v3** - Transcription rapide et prÃ©cise
- ğŸ‘¥ **Diarisation speakers** - Identification automatique des intervenants (NeMo Sortformer)
- ğŸŒ **Multi-langue** - DÃ©tection automatique ou sÃ©lection manuelle (50+ langues)
- ğŸ“„ **Export multi-format** - JSON, TXT, SRT, VTT
- âœï¸ **Renommage speakers** - Personnaliser les noms des intervenants aprÃ¨s transcription

### DictÃ©e en temps rÃ©el
- ğŸ™ï¸ **Enregistrement micro** - DictÃ©e vocale directement depuis le navigateur
- âš¡ **Transcription live** - RÃ©sultats en temps rÃ©el pendant l'enregistrement
- ğŸ”‡ **DÃ©tection silence** - ArrÃªt automatique aprÃ¨s 10s de silence
- ğŸ“Š **VU-mÃ¨tre** - Indicateur visuel du niveau audio

### Post-traitement IA (Ollama)
- ğŸ¤– **IntÃ©gration Ollama** - Connexion Ã  votre instance Ollama locale
- ğŸ“ **Prompts personnalisÃ©s** - CrÃ©ez vos propres prompts de reformulation
- ğŸ“‹ **Copie formatÃ©e** - Export optimisÃ© pour Word/Outlook avec mise en forme

### Interface & UX
- ğŸ–¥ï¸ **Interface web moderne** - Drag & drop, dark mode
- ğŸ“ˆ **Progression dÃ©taillÃ©e** - Suivi en temps rÃ©el de chaque Ã©tape
- ğŸ’¾ **Sauvegarde automatique** - Export direct vers un dossier de votre choix
- ğŸ”Œ **API OpenAI-compatible** - IntÃ©gration directe avec Open WebUI
- ğŸ”„ **Persistance de l'Ã©tat** - L'interface conserve son Ã©tat aprÃ¨s refresh
- ğŸ“‚ **Historique des transcriptions** - Gestion et tÃ©lÃ©chargement des anciennes transcriptions
- ğŸ§ **Ã‰chantillons audio speakers** - Extrait audio pour identifier chaque intervenant

### Performance
- ğŸš€ **GPU acceleration** - OptimisÃ© CUDA avec TF32
- ğŸ’ª **Support RTX 5090** - Compatible avec les derniers GPU NVIDIA
- âš¡ **VAD intÃ©grÃ©** - Filtrage automatique des silences
- ğŸ”— **Fichiers longs** - Traitement par chunks avec harmonisation des speakers
- ğŸ” **RÃ©cupÃ©ration auto** - Reprise aprÃ¨s perte de connexion

## ğŸš€ Quick Start

### PrÃ©requis

- Docker Desktop avec WSL2
- NVIDIA Container Toolkit ([Installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html))
- GPU CUDA-compatible (RTX 3000/4000/5000 series)
- (Optionnel) Token Hugging Face pour d'autres modÃ¨les
- (Optionnel) Ollama pour le post-traitement LLM

### Installation

```bash
# 1. Cloner le repo
git clone https://github.com/VOTRE_USERNAME/MyWhisper.git
cd MyWhisper

# 2. Configuration
copy env.example .env
# Ã‰diter .env si nÃ©cessaire (la diarisation fonctionne sans token)

# 3. Build & Run
docker-compose up -d

# 4. AccÃ¨s
# Interface: http://localhost:8000
# API: http://localhost:8000/v1/audio/transcriptions
```

### Note sur la diarisation

La diarisation utilise **NVIDIA NeMo Sortformer**, un modÃ¨le end-to-end qui :
- Se tÃ©lÃ©charge automatiquement depuis NVIDIA NGC (pas de token requis)
- GÃ¨re nativement les longs fichiers audio sans chunking manuel
- Identifie jusqu'Ã  4 speakers automatiquement

## ğŸ“– Utilisation

### Interface Web

AccÃ©der Ã  `http://localhost:8000` pour l'interface complÃ¨te.

#### Onglet Fichier
1. Glisser-dÃ©poser un fichier audio/vidÃ©o
2. SÃ©lectionner les options (langue, format, diarisation)
3. Activer la sauvegarde automatique si souhaitÃ©
4. Cliquer sur "Transcrire"
5. Renommer les speakers si nÃ©cessaire
6. Retraiter avec l'IA (Ollama) si configurÃ©

#### Onglet DictÃ©e
1. SÃ©lectionner la langue
2. Cliquer sur "DÃ©marrer"
3. Parler dans le micro
4. La transcription apparaÃ®t en temps rÃ©el
5. ArrÃªt automatique aprÃ¨s 10s de silence ou clic sur "ArrÃªter"

#### Onglet Historique
1. Voir toutes les transcriptions passÃ©es
2. TÃ©lÃ©charger dans diffÃ©rents formats (Texte, JSON, SRT, VTT)
3. Visualiser ou supprimer une transcription
4. Configurer la durÃ©e de rÃ©tention dans les paramÃ¨tres

#### Onglet ParamÃ¨tres
1. Configurer la durÃ©e de conservation de l'historique (1-365 jours)
2. Configurer l'URL Ollama (ex: `http://localhost:11434`)
3. SÃ©lectionner un modÃ¨le LLM
4. CrÃ©er des prompts personnalisÃ©s avec `{text}` comme placeholder

### API REST

#### Transcription (OpenAI-compatible)

```bash
curl -X POST http://localhost:8000/v1/audio/transcriptions \
  -F "file=@audio.mp3" \
  -F "language=fr" \
  -F "response_format=json" \
  -F "diarize=true" \
  -F "min_speakers=2" \
  -F "max_speakers=4"
```

#### RÃ©ponse JSON

```json
{
  "text": "Transcription complÃ¨te...",
  "language": "fr",
  "duration": 145.2,
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 5.2,
      "text": "Bonjour, aujourd'hui...",
      "speaker": "SPEAKER_00"
    }
  ]
}
```

#### Endpoints disponibles

| Endpoint | Description |
|----------|-------------|
| `GET /` | Interface web |
| `GET /health` | Health check (status GPU, modÃ¨les) |
| `GET /v1/models` | Liste des modÃ¨les disponibles |
| `POST /v1/audio/transcriptions` | Transcription OpenAI-compatible |
| `POST /v1/audio/transcriptions/stream` | Transcription temps rÃ©el (dictÃ©e) |
| `POST /transcribe` | Endpoint simplifiÃ© |
| `GET /history` | Liste des transcriptions (pagination) |
| `GET /history/{id}` | DÃ©tails d'une transcription |
| `GET /history/{id}/download` | TÃ©lÃ©charger (format: text/json/srt/vtt) |
| `DELETE /history/{id}` | Supprimer une transcription |
| `PUT /history/{id}/speakers` | Mettre Ã  jour les noms des speakers |
| `GET /speaker-sample/{session_id}/{speaker}` | Audio sample d'un speaker |
| `GET /result/{client_id}` | RÃ©cupÃ©rer rÃ©sultat aprÃ¨s dÃ©connexion |

## âš™ï¸ Configuration Open WebUI

Pour utiliser MyWhisper comme moteur STT dans Open WebUI :

1. Aller dans **Settings > Audio > STT**
2. Configurer :
   - **Engine**: OpenAI
   - **Base URL**: `http://whisper-stt:8000/v1`
   - **API Key**: (laisser vide ou mettre une clÃ© factice)
   - **Model**: `whisper-large-v3`

### Configuration rÃ©seau Docker

Si Open WebUI est dans un autre conteneur, ajouter les deux au mÃªme rÃ©seau :

```yaml
# Dans docker-compose.yml de MyWhisper
networks:
  - openwebui_network

networks:
  openwebui_network:
    external: true
```

## ğŸ”§ Configuration avancÃ©e

### Variables d'environnement

| Variable | DÃ©faut | Description |
|----------|--------|-------------|
| `WHISPER_MODEL` | `large-v3` | ModÃ¨le Whisper Ã  utiliser |
| `DEVICE` | `cuda` | Device (cuda/cpu) |
| `COMPUTE_TYPE` | `float16` | Type de calcul (float16/int8) |
| `HF_TOKEN` | - | Token Hugging Face (optionnel, pour autres modÃ¨les HF) |
| `ENABLE_DIARIZATION` | `true` | Activer la diarisation |
| `MAX_FILE_SIZE` | `524288000` | Taille max fichier (500MB) |
| `OLLAMA_BASE_URL` | `http://localhost:11434` | URL de l'instance Ollama |
| `HISTORY_RETENTION_DAYS` | `90` | DurÃ©e conservation historique (jours) |

### Optimisation GPU

Pour RTX 4090/5090 (configuration optimale) :
```env
DEVICE=cuda
COMPUTE_TYPE=float16
```

Pour GPU avec moins de VRAM (8-12GB) :
```env
COMPUTE_TYPE=int8
```

## ğŸ“ Structure du projet

```
MyWhisper/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ env.example
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ PRD_Whisper_STT_Docker.md
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI app + routes
â”‚   â”œâ”€â”€ transcription.py     # Core STT logic (Faster Whisper)
â”‚   â”œâ”€â”€ diarization.py       # Speaker diarization (NeMo Sortformer)
â”‚   â”œâ”€â”€ history.py           # Gestion historique (SQLite)
â”‚   â”œâ”€â”€ patches.py           # Compatibility patches (PyTorch, torchaudio)
â”‚   â”œâ”€â”€ utils.py             # Helpers (formats, validation, speaker samples)
â”‚   â”œâ”€â”€ config.py            # Configuration (Pydantic)
â”‚   â”‚
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ index.html       # Interface web (4 onglets)
â”‚       â”œâ”€â”€ styles.css       # Dark theme moderne
â”‚       â””â”€â”€ app.js           # Alpine.js app
â”‚
â”œâ”€â”€ uploads/                 # Fichiers temporaires (volume)
â”œâ”€â”€ outputs/                 # Exports (volume)
â””â”€â”€ models/                  # ModÃ¨les tÃ©lÃ©chargÃ©s (volume, gitignore)
```

## ğŸ› Troubleshooting

### GPU non dÃ©tectÃ©

```bash
# VÃ©rifier NVIDIA Container Toolkit
docker run --rm --gpus all nvidia/cuda:12.4.1-runtime-ubuntu22.04 nvidia-smi
```

### Erreur CUDA out of memory

RÃ©duire la prÃ©cision dans `.env` :
```env
COMPUTE_TYPE=int8
```

### Diarisation Ã©choue

1. VÃ©rifier que `ENABLE_DIARIZATION=true` dans `.env`
2. S'assurer que le modÃ¨le NeMo peut Ãªtre tÃ©lÃ©chargÃ© (accÃ¨s rÃ©seau)
3. VÃ©rifier les logs : `docker-compose logs -f`

### Erreur "weights_only" PyTorch

Le patch est automatiquement appliquÃ©. Si problÃ¨me, ajouter dans `docker-compose.yml` :
```yaml
environment:
  - TORCH_FORCE_WEIGHTS_ONLY_LOAD=0
```

### Port 8000 dÃ©jÃ  utilisÃ©

Changer le port dans `docker-compose.yml` :
```yaml
ports:
  - "8001:8000"
```

### Ollama non connectÃ©

1. VÃ©rifier qu'Ollama est lancÃ© : `ollama serve`
2. Pour Docker, utiliser `host.docker.internal:11434` au lieu de `localhost`
3. Ou ajouter Ollama au mÃªme rÃ©seau Docker

## ğŸ“Š Performance

**Hardware testÃ©** : RTX 5090

| MÃ©trique | Valeur |
|----------|--------|
| Chargement modÃ¨le | ~5s |
| Transcription 1min audio | < 5s |
| Transcription 1h audio | ~8min |
| VRAM usage (transcription) | ~4GB |
| VRAM usage (+ diarisation) | ~6GB |
| Diarisation overhead | +30-50% temps |

## ğŸ”„ Commandes utiles

```bash
# Build
docker-compose build

# DÃ©marrer
docker-compose up -d

# Logs en temps rÃ©el
docker-compose logs -f

# ArrÃªter
docker-compose down

# Reconstruire et relancer
docker-compose up -d --build

# VÃ©rifier GPU dans le conteneur
docker exec whisper-stt nvidia-smi

# Shell dans le conteneur
docker exec -it whisper-stt bash

# Supprimer cache modÃ¨les
docker exec whisper-stt rm -rf /app/models/*
docker-compose restart
```

## ğŸ†• Changelog

### v1.2.0 (Janvier 2026)
- âœ… **Historique des transcriptions** - Conservation avec durÃ©e configurable
- âœ… **Ã‰chantillons audio speakers** - Extrait audio pour identifier chaque intervenant
- âœ… **Persistance de l'Ã©tat** - L'interface conserve son Ã©tat aprÃ¨s refresh (sessionStorage)
- âœ… **RÃ©cupÃ©ration automatique** - Reprise des rÃ©sultats aprÃ¨s perte de connexion
- âœ… **Harmonisation speakers** - CohÃ©rence des IDs entre chunks pour fichiers longs (>10min)
- âœ… **Anti-doublon Ã©chantillons** - Garantit des extraits audio uniques par speaker
- âœ… **Verrouillage options** - Les options sont verrouillÃ©es pendant le traitement
- âœ… **AmÃ©lioration UX** - RÃ©organisation interface speakers (ID â†’ Input â†’ Audio)

### v1.1.0
- âœ… Historique avec tÃ©lÃ©chargement multi-format
- âœ… Sauvegarde des noms de speakers dans l'historique
- âœ… Cache serveur pour rÃ©cupÃ©ration aprÃ¨s dÃ©connexion
- âœ… Endpoint GET /result/{client_id}

### v1.0.0
- âœ… Transcription Faster Whisper Large v3
- âœ… Diarisation NeMo Sortformer
- âœ… Interface web moderne (Alpine.js)
- âœ… API OpenAI-compatible
- âœ… DictÃ©e en temps rÃ©el avec dÃ©tection silence
- âœ… IntÃ©gration Ollama pour post-traitement LLM
- âœ… Renommage des speakers
- âœ… Sauvegarde automatique (File System Access API)
- âœ… Export formatÃ© Word/Outlook
- âœ… Support RTX 5090 (CUDA 12.4, PyTorch 2.9)
- âœ… Optimisations TF32 et cuDNN

## ğŸ“œ Licence

MIT License

---

**CrÃ©Ã© avec â¤ï¸ pour une transcription audio simple et efficace**
